{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Inference Notebook\n",
    "Notebook is used for training the OCR Engine (or loading a custom model), Inference and Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#% load_ext autoreload\n",
    "#% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # use 2, 3, 4 or 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from pathlib import Path\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "import datetime\n",
    "from Levenshtein import ratio\n",
    "\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(Path(module_path).joinpath(\"src\").as_posix())\n",
    "\n",
    "from custom_model import CustomTrOCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Data and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cm = CustomTrOCR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = cm.load_data(\"../data/extracted/lines_data_cw.json\")\n",
    "print(f\"Shape of full provided data set {df.shape}\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = cm.prepare_data(outlier_threshold=110, strip_whitespaces=True)\n",
    "# Save data for eda \n",
    "df.to_json(\"../data/extracted/preprocessed_lines_data_cw.json\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "______\n",
    "# Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "### Execute this cell only once to get the untrained base stage ###\n",
    "###################################################################\n",
    "\n",
    "# Load the model from huggingface\n",
    "#cm.load_model('microsoft/trocr-base-stage1', source='huggingface')\n",
    "\n",
    "# Save the model to a directory\n",
    "#cm.dump_model(\"../models/trocr_base_stage1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/Custom_Split_64b_10e_ep5\n",
      "../models/Custom_Split_64b_10e_ep3\n",
      "../models/Custom_Split_64b_10e_ep6\n",
      "../models/Custom_Split_64b_10e_ep8\n",
      "../models/Custom_Split_64b_10e_ep4\n",
      "../models/Custom_Split_32b_5e_50subsample_ep0\n",
      "../models/Custom_Split_32b_5e_50subsample_ep4\n",
      "../models/Custom_Split_64b_10e_ep9\n",
      "../models/Custom_Split_32b_5e_50subsample_ep2\n",
      "../models/Custom_Split_64b_10e_ep0\n",
      "../models/Custom_Split_32b_5e_50subsample_ep3\n",
      "../models/Custom_Split_64b_10e_ep1\n",
      "../models/Custom_Split_64b_10e_ep2\n",
      "../models/Custom_Split_64b_10e_ep7\n",
      "../models/trocr_base_stage1\n",
      "../models/Custom_Split_32b_5e_50subsample_ep1\n"
     ]
    }
   ],
   "source": [
    "# Enlist current models available in models dir\n",
    "cm.list_current_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the base model from local directory after loading and saving the model from huggingface\n",
    "cm.load_model(\"../models/trocr_base_stage1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "_____\n",
    "# Fine Tuning\n",
    "Skip this section if you want to use a already pretrained custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Custom_Split_64b_10e_XXX\"\n",
    "SAVE_DIR = \"../models/\" + MODEL_NAME\n",
    "N_EPOCHS = 10\n",
    "\n",
    "assert MODEL_NAME != \"Custom_Split_64b_10e\", print(\"Do not overwrite master model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cm.train_model(test_size=0.1,\n",
    "               val_size=0.1,\n",
    "               batch_size=64,\n",
    "               shuffle=True,\n",
    "               epochs=N_EPOCHS,\n",
    "               save_dir=SAVE_DIR,\n",
    "               take_subsample=False,               # Set to False to train on full dataset\n",
    "               #subsample_size=0.5,\n",
    "               remove_chinese_letter=True,\n",
    "               use_custom_train_test_split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "_______\n",
    "# Evaluate Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n",
    "# Loss plot settings\n",
    "sns.lineplot(x=np.arange(0, len(cm.history_loss)),\n",
    "             y=cm.history_loss,\n",
    "             ax=axes[0])\n",
    "axes[0].set_title(\"Cross Entropy Loss after each Epoch\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "# CER plot settings\n",
    "sns.lineplot(x=np.arange(0, len(cm.history_cer)),\n",
    "             y=cm.history_cer,\n",
    "             ax=axes[1],\n",
    "             color=\"red\")\n",
    "axes[1].set_title(\"Character Error Rate (CER) after each Epoch\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"CER\")\n",
    "# Save fig in img dir\n",
    "plt.savefig(f\"../img/{MODEL_NAME}_eval_{str(datetime.datetime.now()).replace(':', '').strip()}.png\", dpi=256)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "__________\n",
    "```\n",
    "For the evaluation of the Test Set, please go to evaluation notebook.\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}